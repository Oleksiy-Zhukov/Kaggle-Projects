# Titanic with XGBoost Classifier | Kaggle Notebook

In this notebook, I aim to create the most accurate solution possible for the Titanic - Machine Learning from Disaster competition using XGBoosting algorithms. By exploring and analyzing the provided dataset, I will develop and fine-tune my model to achieve the highest possible accuracy score. Through this project, I hope to demonstrate the effectiveness of XGBoosting algorithms in solving real-world machine learning problems.

## Geting started

### Dependencies

* Pandas python library (https://pandas.pydata.org/)
* Numpy python library (https://numpy.org/)
* Matplotlib python library (https://matplotlib.org/stable/index.html)
* Seaborn python library (https://seaborn.pydata.org/index.html)
* Scikit-learn python library (https://scikit-learn.org/stable/)
* XGBoost python package (https://xgboost.readthedocs.io/en/stable/python/index.html)

### Usage

This project is contained within a single Jupyter Notebook file called titanic.ipynb, which can be found either in this repository or on my Kaggle page ([link](https://www.kaggle.com/code/zhukovoleksiy/titanic-with-xgbclassifier)). By opening the notebook, you can view all of the code and its corresponding results in a single page. Simply scroll through the notebook to explore the examples and see the visualizations.

## Data

* Titanic - Machine Learning from Disaster Dataset (https://www.kaggle.com/competitions/titanic/data)

## Contact

* My Kaggle profile: https://www.kaggle.com/zhukovoleksiy
* My LinkedIn profile: https://www.linkedin.com/in/oleksiizhukov/
* My GitHub profile: https://github.com/Oleksiy-Zhukov
